#!/usr/bin/env python
from deployment import Deployment
import sys, os
import argparse

def main():
    parser = argparse.ArgumentParser("Deploy the Fulfillment application to AWS Cloud Formation")

    #set up default paths
    thisdir = os.path.dirname(os.path.realpath(__file__))
    rootdir = os.path.abspath(os.path.join(thisdir, ".."))
    scriptdir = os.path.join(thisdir, "scripts")
    template_path = os.path.join(scriptdir, "aws_template.json")
    bootstrap_path = os.path.join(scriptdir, "base_bootstrap.sh")
    logfile = os.path.join("/var/log/balihoo/fulfillment","deployment.log")

    #command line options for debug / test and manual runs
    parser.add_argument('-d','--rootdir', help='the project root', default=rootdir)
    parser.add_argument('-l','--logfile', help='the log file for the deployment process', default=logfile)
    parser.add_argument('--s3dir', help='the S3 sub dir to use (skips packaging and upload)')
    parser.add_argument('--template', help='the template to use for stack creation', default=template_path)
    parser.add_argument('--bootstrap', help='the bootstrap script to use on the ec2 instances', default=bootstrap_path)
    parser.add_argument('--pkgdir', help='path of the package to use (skips packaging)')
    parser.add_argument('--nocf', help='do not create a cloud formation stack', action='store_true')
    parser.add_argument('--noupload', help='do not upload to S3', action='store_true')
    parser.add_argument('--debug', help='include debugging utilities', action="store_true")

    #configs from cmd line or environment: these are things that could be different per deployed environment
    parser.add_argument('--region', help='the AWS region', default='us-west-2')
    parser.add_argument('--s3bucket', help='the S3 bucket to use', default='balihoo.dev.fulfillment')
    parser.add_argument('--ssh_keyname', help='the ssh keyname pair to use for ssh access', default='paul-ami-pair')
    parser.add_argument('--worker_instance_type', help='worker ec2 instance (e.g. m1.small)', default='m1.small')
    parser.add_argument('--dash_instance_type', help='dashboard ec2 instance (e.g. m1.small)', default='t1.micro')
    parser.add_argument('--min_instances', help='minimum number of ec2 worker instances', default='1')
    parser.add_argument('--max_instances', help='maximum number of ec2 worker instances', default='5')
    parser.add_argument('--access_ip_mask', help='ip range allowed to access fulfillment', default='207.170.207.66/32')
    parser.add_argument('--web_port', help='the tcp port for the dashboard', default='80')
    parser.add_argument('--pyversion', help='the python version to install on the instance', default='2.7.7')
    parser.add_argument('--veversion', help='the virtualenv version to install on the instance', default='1.11.6')
    parser.add_argument('--dasheip', help='the eip for the dashboard', default=None)
    parser.add_argument('--access_key', help='the aws access key used for deployment', default=os.environ["AWS_ACCESS_KEY_ID"])
    parser.add_argument('--secret_key', help='the aws secret key used for deployment', default=os.environ["AWS_SECRET_ACCESS_KEY"])
    parser.add_argument('--env', help='the deployment environment: dev, stage, etc.', default='dev')

    args = parser.parse_args()

    pkgdir = args.pkgdir

    #less than ideal. Should gen these from a single source
    config = Deployment.Config(
        access_key=args.access_key,
        secret_key=args.secret_key,
        region=args.region,
        s3bucket=args.s3bucket,
        ssh_keyname=args.ssh_keyname,
        worker_instance_type=args.worker_instance_type,
        dash_instance_type=args.dash_instance_type,
        min_instances=args.min_instances,
        max_instances=args.max_instances,
        access_ip_mask=args.access_ip_mask,
        web_port=args.web_port,
        pyversion=args.pyversion,
        veversion=args.veversion,
        dasheip=args.dasheip,
        env=args.env,
        debug=args.debug
    )

    d = Deployment(args.logfile, config)

    s3dir = args.s3dir

    if not (pkgdir or args.s3dir):
        pkgdir = d.package(args.rootdir)
    if not (args.s3dir or args.noupload):
        s3dir = d.upload(pkgdir)
    if not args.nocf:
        d.create_stack(s3dir, args.template, args.bootstrap)

if __name__ == "__main__":
    main()
